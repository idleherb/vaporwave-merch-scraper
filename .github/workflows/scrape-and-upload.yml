name: scrape-and-upload

on:
  schedule:
    # Run workflow every 4 hours
    - cron: "0 */4 * * *"
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    - name: Set up Poetry
      uses: Gr1N/setup-poetry@v9
    - name: Set up Python 3.12
      uses: actions/setup-python@v5
      with:
        python-version: "3.12"
        cache: "poetry"
    - name: Install dependencies
      run: |
        poetry install
    - name: Run scraper
      run: |
        poetry run python -m scraper.main > bandcamp_merch.json
    - name: Store json results
      uses: actions/upload-artifact@v4
      with:
        name: scraping-results
        path: bandcamp_merch.json
        retention-days: 1

  upload-results:
    needs: scrape
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
    - uses: actions/checkout@v4
    - name: Create folder for syncing
      run: |
        mkdir -p tmp
    - uses: actions/download-artifact@v4
      with:
        name: scraping-results
        path: tmp/
    - name: Upload scraping results to s3 bucket
      uses: jakejarvis/s3-sync-action@master
      with:
        args: --acl public-read
      env:
        AWS_S3_BUCKET: ${{ secrets.AWS_BUCKET }}
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        SOURCE_DIR: "tmp"
    - name: Update last-run timestamp
      run: |
        date -u +"%Y-%m-%dT%H:%M:%SZ" > .github/last-run.txt
        git config user.name "github-actions[bot]"
        git config user.email "github-actions[bot]@users.noreply.github.com"
        git add .github/last-run.txt
        git commit -m "Update last-run timestamp"
        git push
